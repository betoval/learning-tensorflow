{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras-basics.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPviCBLz0F9eR0SoKpDayOL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/betoval/learning-tensorflow/blob/master/keras_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49eVpTHXojo8",
        "colab_type": "code",
        "outputId": "4eee503e-9ba5-4596-d3b1-ccf2a6c86596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYgxrFd6pFv0",
        "colab_type": "text"
      },
      "source": [
        "Keras\n",
        "\n",
        "A High-Level API for TensorFlow 2\n",
        "\n",
        "We'll work with keras within TF2. The module is `tf.keras`.\n",
        "Keras is based on the concept of neural network called Sequence, which is a linear stack of layers.\n",
        "\n",
        "Workflow:\n",
        "1. Build\n",
        "2. Compile\n",
        "3. Fit\n",
        "4. Evaluate\n",
        "5. Make predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8Vot2I0pdDX",
        "colab_type": "code",
        "outputId": "c4b7fb82-234f-4283-cff4-f437f9980a36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from tensorflow.keras import backend as K #low-level operations, such as convolutions and tensor products\n",
        "const = K.constant([[42,24],[11,99]], dtype=tf.float16, shape=[2,2]) #like tf.constant\n",
        "const"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float16, numpy=\n",
              "array([[42., 24.],\n",
              "       [11., 99.]], dtype=float16)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALz4oG2j0qcS",
        "colab_type": "text"
      },
      "source": [
        "**Create a Sequential model**\n",
        "\n",
        "Acquire data .mnist which includes hand-drawn numerals, each on a 28 x 28 pixel grid.\n",
        "\n",
        "The pixel intensities are represented by integers (from 0 to 255)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-lHLONk093d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
        "epochs = 10 #number of times we present data to the model\n",
        "batch_size = 32 # 32 is default in fit method"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37E6mv7i3Btn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we divide by 255.0 to scale the pixel intensities down to 0-1 range. \n",
        "#This also converts the values to floats\n",
        "train_x, test_x = train_x/255.0, test_x/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1Yqff70393M",
        "colab_type": "text"
      },
      "source": [
        "*Model definition*\n",
        "\n",
        "We create a Sequential model. This is the simplest kind of keras  model.\n",
        "\n",
        "1. The `Flatten` layer converts each input image to a 1D array.\n",
        "\n",
        "2. `Dense` is a fully connected layer. This example uses 512 neurons, whose inputs are passed through a ReLU (non-linear) activation function.\n",
        "\n",
        "3. `Dropout` randomly turns off a fraction (in this case 0.2) of neurons in the previous layer.\n",
        "\n",
        "4. The final Dense layer has the function softmax which assigns probabilities to each of the possible 10 output neurons.\n",
        "\n",
        "It is not necessary to inlude `input_shape=(28,28)`. In general, keras will wait until it knows the shape before it actually builds the model.\n",
        "\n",
        "Instead of 'relu' we could also write `activation=tf.nn.relu`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuD8_GM-4BHK",
        "colab_type": "code",
        "outputId": "2f84a825-b18a-4d9a-9584-070813014267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model1 = tf.keras.models.Sequential([\n",
        "                                     tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "                                     tf.keras.layers.Dense(512,activation='relu'),\n",
        "                                     tf.keras.layers.Dropout(0.2),\n",
        "                                     tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "])\n",
        "model1.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_31 (Flatten)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XTWB6MC7cQl",
        "colab_type": "text"
      },
      "source": [
        "**Compile the model**\n",
        "\n",
        "In this example, we have chosen the Adam optimization algorithm (an extension of the stochastic gradient descent). The `optimizer` is the method by which the wights of the weighted connections in the model are adjusted to decrease loss.\n",
        "\n",
        "`loss` is a measure of the difference between the required output of the model and the actual output, and `metrics` is how we evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16BzWdav7gQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer1 = tf.keras.optimizers.Adam()\n",
        "model1.compile(optimizer = optimizer1, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mTOpbKd85Gy",
        "colab_type": "text"
      },
      "source": [
        "**Train model**\n",
        "\n",
        "We use the `fit()` method to train the model\n",
        "\n",
        "Runs for 10 epochs showing the loss and the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwW5F8Qm8-rn",
        "colab_type": "code",
        "outputId": "42aed60d-3115-4112-9657-17f001d2e491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model1.fit(train_x, train_y, batch_size=batch_size, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 9s 144us/sample - loss: 0.2195 - accuracy: 0.9359\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 9s 143us/sample - loss: 0.0983 - accuracy: 0.9707\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.0700 - accuracy: 0.9788\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.0546 - accuracy: 0.9824\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 9s 144us/sample - loss: 0.0430 - accuracy: 0.9860\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.0374 - accuracy: 0.9877\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.0315 - accuracy: 0.9897\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.0263 - accuracy: 0.9912\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 136us/sample - loss: 0.0242 - accuracy: 0.9919\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.0221 - accuracy: 0.9926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f91c58ed358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Tc92ImT5lf",
        "colab_type": "text"
      },
      "source": [
        "Now, we check the accuracy of the model using `evaluate()`.\n",
        "We obtained a loss of 0.16 and an accuracy of 0.97 on the test data. This means that out of 100 test data points, 97 were correctly identified by the model. If we run `fit()` again, then the values of `loss` and `accuracy` may change"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0k0dCqmTYGf",
        "colab_type": "code",
        "outputId": "dd1f8ae8-60e2-4771-cd5b-781f3b9a556f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model1.evaluate(test_x, test_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 76us/sample - loss: 0.0735 - accuracy: 0.9813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07352110323294346, 0.9813]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd9iSkJmaGrK",
        "colab_type": "text"
      },
      "source": [
        "**Another way to create a Sequential model**\n",
        "\n",
        "Now, we use the `add` method to add layers to the `Sequential` model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXSQyMnHaWqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#building the neural network using add\n",
        "model2 = tf.keras.models.Sequential();\n",
        "model2.add(tf.keras.layers.Flatten())\n",
        "model2.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model2.add(tf.keras.layers.Dropout(0.2))\n",
        "model2.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
        "#compile the model\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax9_RITN8KUz",
        "colab_type": "code",
        "outputId": "a2e887f0-a626-4091-effe-a7543ac46e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "#train the model using fit\n",
        "model2.fit(train_x, train_y, batch_size=batch_size, epochs=epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.2196 - accuracy: 0.9351\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 134us/sample - loss: 0.0954 - accuracy: 0.9709\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0677 - accuracy: 0.9783\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.0550 - accuracy: 0.9829\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.0430 - accuracy: 0.9861\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.0359 - accuracy: 0.9879\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.0321 - accuracy: 0.9888\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 134us/sample - loss: 0.0277 - accuracy: 0.9906\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.0241 - accuracy: 0.9919\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.0222 - accuracy: 0.9927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f91c3ccb438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUsupUeg8ZSe",
        "colab_type": "code",
        "outputId": "1cac11b9-a17e-44c2-e6f7-11d756e269a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#evaluate the performance of the model using evaluate\n",
        "model2.evaluate(test_x, test_y)\n",
        "#the performance is identical to the one presented earlier"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 74us/sample - loss: 0.0751 - accuracy: 0.9821\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07508908181103616, 0.9821]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzVj4eVz93C5",
        "colab_type": "text"
      },
      "source": [
        "**The keras functional API**\n",
        "\n",
        "The API lets you build much more complex architectures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjbolUiIobkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the setup code is the same\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
        "train_x, test_x = train_x/255.0, test_x/255.0\n",
        "epochs=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8rI8EXPsQwB",
        "colab_type": "text"
      },
      "source": [
        "We build **the model** as follows. Note that layers are callable on tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSwp4td_pY9n",
        "colab_type": "code",
        "outputId": "9e18c456-a98a-4721-a26a-d4170a1476eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "inputs = tf.keras.Input(shape=(28,28)) #placeholder tensor\n",
        "x = tf.keras.layers.Flatten()(inputs)\n",
        "x = tf.keras.layers.Dense(512, activation='relu',name='d1')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "predictions = tf.keras.layers.Dense(10, activation=tf.nn.softmax, name='d2')(x)\n",
        "\n",
        "model3 = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
        "model3.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28)]          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "d1 (Dense)                   (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "d2 (Dense)                   (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCPMu0bos9lL",
        "colab_type": "text"
      },
      "source": [
        "The rest of the code is about compiling, training and evaluating, and it is the same as the previous examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om5LLj4ltEg2",
        "colab_type": "code",
        "outputId": "74a884de-78d8-4a44-fd54-3f4f582dabce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model3.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model3.fit(train_x, train_y, batch_size=32, epochs=epochs)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2183 - accuracy: 0.9352\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0968 - accuracy: 0.9706\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0692 - accuracy: 0.9788\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0532 - accuracy: 0.9840\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0432 - accuracy: 0.9859\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0357 - accuracy: 0.9882\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0306 - accuracy: 0.9900\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0265 - accuracy: 0.9913\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0239 - accuracy: 0.9918\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0204 - accuracy: 0.9933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6581bc6128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtXdjrbtvWhF",
        "colab_type": "code",
        "outputId": "f3b7bc2a-c7fb-441d-b0a0-bf62ea6ce1a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model3.evaluate(test_x, test_y)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0766 - accuracy: 0.9811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07659736275672913, 0.9811000227928162]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4h_q2RieUOy",
        "colab_type": "text"
      },
      "source": [
        "**Data Pipelines**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z216BMpre1dS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b19803f-bc6c-43cc-8c2f-9dfb926fb7ba"
      },
      "source": [
        "#the setup code is the same\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
        "train_x, test_x = train_x/255.0, test_x/255.0\n",
        "epochs=10\n",
        "batch_size = 32\n",
        "buffer_size = 10000 #shuffle the data before each epoch"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn1w5BuIfBYN",
        "colab_type": "text"
      },
      "source": [
        "The data passed into the fit method (the one we use to \"train\" the model) can be also passed as dataset using `tf.data.Dataset()`.\n",
        "\n",
        "`from_tensor_slices()` converts the Numpy arrays into a dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1RDdZ_OgBxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preparing the train data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(32).shuffle(10000)\n",
        "train_dataset = train_dataset.map(lambda x, y: (tf.image.random_flip_left_right(x))) #flips one image in two of them across the y axis\n",
        "train_dataset = train_dataset.repeat() #the data set will be re-fed (like a loop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-p66Jjpkb48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preparing the test data\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(32).shuffle(10000)\n",
        "test_dataset = train_dataset.repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8Ck3-HclV8k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "8ba85e0e-95cc-4ea2-e95f-62be9c40b07a"
      },
      "source": [
        "#passing the data into fit\n",
        "steps_per_epoch = len(train_x//batch_size #required because of the repeat in the dataset\n",
        "#compiling\n",
        "#i need to define this model but i don't know how\n",
        "#i tried to use the Sequential model but it didn't work\n",
        "model5.compile(tf.kers.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model5.fit(train_dataset, batch_size=batch_size, epochs=epochs, steps_per_epoch=steps_per_epoch)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-42917dfe1c79>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    model5.compile(tf.kers.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za5zPam5sFZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}